{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS Lambda and PyWren to make HTTP Requests in Parallel\n",
    "\n",
    "A common task for computational social scientists is making HTTP requests to access and process web data. It can be quite limiting to make these requests serially, though. When we do, the amount of data we are able to collect is limited both by our internet bandwidth and machine's ability to sequentially process the data.\n",
    "\n",
    "It would be much better to parallelize this workflow. In this notebook, we're going to walk through how we can make API requests and perform simple calculations on text data in parallel using AWS Lambda and PyWren. Specifically, we will call the [Google Books API](https://developers.google.com/books/docs/v1/getting_started) in parallel on a list of ISBNs, calculating the number of words used in the description for each book in our ISBN list (see workflow below). Word count is a simple metric (used here as a proof-of-concept), but it would also be possible to perform other Natural Language Processing routines using this same approach. Such a cloud workflow allows us to gather and process far greater amounts of data than would be otherwise possible on our local machines.\n",
    "\n",
    "![AWS Serverless Workflow](pywren_workflow.png)\n",
    "\n",
    "If you haven't already, please [install/configure PyWren](http://pywren.io/pages/gettingstarted.html) in order to run this notebook. Then, let's import our packages and read in the list of ISBN numbers we'll be working with in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywren\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('isbn.txt') as file:\n",
    "    isbn_list = [isbn.strip() for isbn in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of ISBNs in list: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"# of ISBNs in list:\", len(isbn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify search terms to return metadata from the Google Books dataset by entering a query string after the ?q= string in the API URL. For instance, we could specify an individual ISBN number for a book, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.googleapis.com/books/v1/volumes?q=isbn:0435910108\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "print(url + isbn_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the metadata for a single book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'books#volumes',\n",
       " 'totalItems': 1,\n",
       " 'items': [{'kind': 'books#volume',\n",
       "   'id': 'DGALPwfF9fAC',\n",
       "   'etag': 'HkmqpoiJi/s',\n",
       "   'selfLink': 'https://www.googleapis.com/books/v1/volumes/DGALPwfF9fAC',\n",
       "   'volumeInfo': {'title': 'The Best American Essays of the Century',\n",
       "    'authors': ['Joyce Carol Oates', 'Robert Atwan'],\n",
       "    'publisher': 'Mariner Books',\n",
       "    'publishedDate': '2000',\n",
       "    'description': 'An anthology of fifty-five essays on a variety of topics features contributions by F. Scott Fitzgerald, James Baldwin, Stephen Jay Gould, Alice Walker, Maya Angelou, and other notable twentieth-century literary masters.',\n",
       "    'industryIdentifiers': [{'type': 'ISBN_10', 'identifier': '0618155872'},\n",
       "     {'type': 'ISBN_13', 'identifier': '9780618155873'}],\n",
       "    'readingModes': {'text': False, 'image': False},\n",
       "    'pageCount': 596,\n",
       "    'printType': 'BOOK',\n",
       "    'categories': ['Literary Collections'],\n",
       "    'averageRating': 4,\n",
       "    'ratingsCount': 1,\n",
       "    'maturityRating': 'NOT_MATURE',\n",
       "    'allowAnonLogging': False,\n",
       "    'contentVersion': '0.2.2.0.preview.0',\n",
       "    'panelizationSummary': {'containsEpubBubbles': False,\n",
       "     'containsImageBubbles': False},\n",
       "    'imageLinks': {'smallThumbnail': 'http://books.google.com/books/content?id=DGALPwfF9fAC&printsec=frontcover&img=1&zoom=5&source=gbs_api',\n",
       "     'thumbnail': 'http://books.google.com/books/content?id=DGALPwfF9fAC&printsec=frontcover&img=1&zoom=1&source=gbs_api'},\n",
       "    'language': 'en',\n",
       "    'previewLink': 'http://books.google.com/books?id=DGALPwfF9fAC&pg=PP1&dq=isbn:0618155872&hl=&cd=1&source=gbs_api',\n",
       "    'infoLink': 'http://books.google.com/books?id=DGALPwfF9fAC&dq=isbn:0618155872&hl=&source=gbs_api',\n",
       "    'canonicalVolumeLink': 'https://books.google.com/books/about/The_Best_American_Essays_of_the_Century.html?hl=&id=DGALPwfF9fAC'},\n",
       "   'saleInfo': {'country': 'US',\n",
       "    'saleability': 'NOT_FOR_SALE',\n",
       "    'isEbook': False},\n",
       "   'accessInfo': {'country': 'US',\n",
       "    'viewability': 'NO_PAGES',\n",
       "    'embeddable': False,\n",
       "    'publicDomain': False,\n",
       "    'textToSpeechPermission': 'ALLOWED',\n",
       "    'epub': {'isAvailable': False},\n",
       "    'pdf': {'isAvailable': False},\n",
       "    'webReaderLink': 'http://play.google.com/books/reader?id=DGALPwfF9fAC&hl=&printsec=frontcover&source=gbs_api',\n",
       "    'accessViewStatus': 'NONE',\n",
       "    'quoteSharingAllowed': False}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(url + isbn_list[50])\n",
    "data = r.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this data, we can compute metrics based on it, such as determining the number of words in a given book's description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = data['items'][0]['volumeInfo']['description']\n",
    "wc = len(description.split())\n",
    "wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's formalize this process so that we can determine the number of words that are in ***each*** description in a list of ISBN numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_wc(isbn_list):\n",
    "    '''\n",
    "    Takes in a list of ISBNs and returns a list of description\n",
    "    word counts corresponding to each ISBN (via the Google\n",
    "    Books API).\n",
    "    '''\n",
    "    wc_list = []\n",
    "    for isbn in isbn_list:\n",
    "        r = requests.get(url + isbn)\n",
    "        data = r.json()\n",
    "        # Try to get description, but if there is none, set\n",
    "        # word count to be 0 for that book\n",
    "        try:\n",
    "            description = data['items'][0]['volumeInfo']['description']\n",
    "            wc_list.append(len(description.split()))\n",
    "        except KeyError:\n",
    "            wc_list.append(0)\n",
    "            pass\n",
    "    return wc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call our function and it will sequentially request information and calculate the description word count for each one of our ISBNs in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - Serial:  81.25825929641724\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "wc_list = get_desc_wc(isbn_list)\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - Serial: \", time_elapsed)\n",
    "\n",
    "plt.hist(wc_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit slow (exactly how slow will be variable and heavily based on your internet connection!), though, and could benefit from parallelization. One way we can do this in a \"serverless\" fashion is by using PyWren to invoke AWS Lambda functions that make these ISBN API calls (and calculate the description word count) in parallel. To give each Lambda worker a single ISBN to work with, we can write another function that handles each ISBN individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_wc_parallel(isbn):\n",
    "    '''\n",
    "    Takes in a single ISBN and returns a single description\n",
    "    word count corresponding to the input ISBN (via the Google\n",
    "    Books API).\n",
    "    '''\n",
    "    wc = 0\n",
    "    r = requests.get(url + isbn)\n",
    "    data = r.json()\n",
    "    try:\n",
    "        description = data['items'][0]['volumeInfo']['description']\n",
    "        wc = len(description.split())\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then use PyWren and AWS Lambda to remotely execute this function on each ISBN in our ISBN list in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - AWS Lambda Solution 24.50263476371765\n"
     ]
    }
   ],
   "source": [
    "pwex = pywren.default_executor()\n",
    "start = time.time()\n",
    "\n",
    "# Apply get_desc_wc to list of ISBNs, which will automatically be remotely executed by AWS Lambda in parallel\n",
    "futures = pwex.map(get_desc_wc_parallel, isbn_list)\n",
    "\n",
    "# get_all_results waits until all of the futures have been executed and then returns their results\n",
    "# note that this is an alternative to the list comprehension in the lecture video\n",
    "wc_list = pywren.get_all_results(futures)\n",
    "\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - AWS Lambda Solution\", time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wc_list); # should mirror plot derived from serial execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the results that PyWren has given us (see above), we can see that we have the same result, but it takes a lot less time to execute when we make API calls in parallel, even accounting for all of the communications between us and AWS and time spent invoking and setting up our Lambda workers. \n",
    "\n",
    "This means that we should be able to gather a lot more data than we would be capable of gathering serially!\n",
    "\n",
    "So, let's say that we had 2000 ISBNs instead of just 500. We can simulate this by extending our list with copies of the existing ISBNs and then rerunning our code with this new data size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - Serial:  232.80473399162292\n"
     ]
    }
   ],
   "source": [
    "isbn_list = isbn_list * 4\n",
    "\n",
    "start = time.time()\n",
    "wc_list = get_desc_wc(isbn_list)\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - Serial: \", time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, operating serially, this would take us awhile to perform all of these API calls (again, depending on your machine and internet connection). What about in parallel with Lambda and PyWren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - AWS Lambda Solution 31.46332804911339\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Apply get_desc_wc to list of ISBNs, which will automatically be remotely executed by AWS Lambda in parallel\n",
    "futures = pwex.map(get_desc_wc_parallel, isbn_list)\n",
    "\n",
    "# get_all_results waits until all of the futures have been executed and then returns their results\n",
    "# note that this is an alternative to the list comprehension in the lecture video\n",
    "wc_list = pywren.get_all_results(futures)\n",
    "\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - AWS Lambda Solution\", time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're around 5-10x faster than serial. Currently, though, note that we're invoking a devoted Lambda function instance to request metadata ***for each*** of our ISBNs. Imagine, though, that we have 6000 ISBNs that we want to process in parallel. This will exceed the [maximum of number of concurrent Lambda workers (3000)](https://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html) and, thus, our scaling capabilities will be limited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - AWS Lambda Solution 125.87248802185059\n"
     ]
    }
   ],
   "source": [
    "isbn_list = isbn_list * 3 # 6000 ISBNs\n",
    "start = time.time()\n",
    "\n",
    "# Apply get_desc_wc to list of ISBNs, which will automatically be remotely executed by AWS Lambda in parallel\n",
    "futures = pwex.map(get_desc_wc_parallel, isbn_list)\n",
    "\n",
    "# get_all_results waits until all of the futures have been executed and then returns their results\n",
    "# note that this is an alternative to the list comprehension in the lecture video\n",
    "wc_list = pywren.get_all_results(futures)\n",
    "\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - AWS Lambda Solution\", time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to get around this with PyWren is to make ***multiple API requests on a single set of 3000 simultaneous Lambda workers*** that we have already invoked to perform the first round of API requests. These requests do not take much time to perform on their own and can be performed concurrently. So, for instance, we might construct batch sizes of 2 ISBNs for each Lambda function to request information about and process (spread across 3000 parallel Lambda functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 2\n"
     ]
    }
   ],
   "source": [
    "n = 2 # subdivide list of ISBNs into batches of size 2\n",
    "isbn_batches = [isbn_list[i:i + n] for i in range(0, len(isbn_list), n)]\n",
    "print(len(isbn_batches), len(isbn_batches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (in seconds) - AWS Lambda Solution 41.85841941833496\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Apply get_desc_wc to list of ISBNs, which will automatically be remotely executed by AWS Lambda in parallel\n",
    "# each invocation of get_desc_wc is passed a length-2 list of ISBNs\n",
    "futures = pwex.map(get_desc_wc, isbn_batches)\n",
    "\n",
    "# get_all_results waits until all of the futures have been executed and then returns their results\n",
    "# will return list of length-2 lists -- need to flatten this for further processing\n",
    "wc_list = pywren.get_all_results(futures) \n",
    "\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Time elapsed (in seconds) - AWS Lambda Solution\", time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! By constructing mini-batches of our ISBNs, we maximize the use of the lambda workers that we have invoked without needing to invoke and set up another set of workers, as in our initial PyWren solution above. This is also a fairly scalable solution --  as we increase our data size, we will continue to see our parallel solution improve upon our serial one (so long as we don't go beyond the maximum Lambda timeout window for each Lambda worker)."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
